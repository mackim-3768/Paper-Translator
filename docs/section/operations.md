# 성능 및 운영 리스크

이 문서는 논문 번역 서비스의 **성능 목표**와 **운영 상의 제약/정책**을 정의합니다. 특히

- 업로드 용량/페이지 수 제한
- 토큰/비용 및 응답 속도 관리
- Job 큐 폭주 방지, Rate Limit, 동시성 제어
- 번역 중단/실패 시 일관성 및 재시도 전략
- 모니터링/알림 및 용량 계획

을 다룹니다.

---

## 1. 성능 목표 및 제약

### 1.1 사용자 관점 목표 (예시)

- **단일 논문 업로드 후 첫 응답**
  - `/upload` 요청: 수 초 이내(파일 저장 및 Job 생성만 포함).
- **상태 조회 응답 시간**
  - `/status/{job_id}`: 200ms 내(네트워크 제외)
- **번역 완료까지의 시간**
  - 일반적인 10~20페이지 논문: 수 분 이내 완료를 목표로 함.

### 1.2 시스템 관점 제약

- LLM API의 토큰/속도 제한에 강하게 영향을 받음.
- PDF 파싱 및 렌더링은 CPU/메모리 집약적 작업이므로, **동시 처리 개수**를 제한해야 함.

---

## 2. 업로드 파일 크기 및 페이지 수 제한

### 2.1 정책

- **파일 크기 제한**
  - 예시: 최대 **30MB**
  - 설정값으로 관리 (`MAX_UPLOAD_SIZE_MB`).

- **페이지 수 제한**
  - 예시: 최대 **100페이지**
  - PDF 파싱 시 페이지 수를 계산하여 초과 시 즉시 실패 처리.

### 2.2 구현 방향

- API 레벨
  - FastAPI에서 `Content-Length` 확인 후, 최대 크기 초과 시 요청 Body를 파싱하지 않고 413 응답.

- 비즈니스 레벨
  - `PDFParser`가 페이지 수를 파악한 뒤, 정책을 위반하면 Job을 `FAILED`로 설정하고 적절한 `error_code`/`error_message`를 기록.

---

## 3. 토큰/비용 및 응답 속도 관리

### 3.1 청크 단위 토큰 관리

- 번역 대상 텍스트를 **청크**로 분할할 때, LLM 모델의 최대 토큰 수를 고려.
  - 예: `gpt-4.1-mini` 기준 context 한도 내에서 여유 버퍼를 두고 최대 입력 토큰을 제한.
- 청크 크기 전략 예시
  - 문단/섹션 단위로 기본 분리.
  - 문단이 너무 길 경우, 글자 수 기준으로 추가 분리 (예: 2,000~3,000자 단위).

### 3.2 비용 관리

- **Job 단위 토큰 상한** (soft limit)
  - Job당 예상 토큰 수를 계산하여 일정 수준(예: 수십만 토큰)을 넘을 경우, 경고 또는 Job 거절.

- **전역 일일 토큰 상한** (옵션)
  - 운영 환경에서 하루 단위 전체 토큰 사용량을 모니터링하여, 상한에 근접하면 신규 Job 접수를 제한(429/503)하는 방안 고려.

### 3.3 응답 속도 관리

- LLM 호출은 네트워크/모델 지연이 크므로, **병렬 번역 개수**를 제한
  - 예: 워커 프로세스당 동시 LLM 요청 N개 (환경 변수로 조정).
- 느린 Job (예: 특이하게 긴 논문)에 대해서는
  - `/status` 응답에 `progress` 또는 `processed_pages` 등을 추가해 사용자가 진행 상황을 알 수 있게 함.

---

## 4. Job 큐 폭주, Rate Limit 및 동시성 제어

### 4.1 Job 큐 정책

- **큐 길이 상한** 정의
  - 예: 대기 중인 `PENDING` Job이 일정 개수(예: 1,000개)를 넘으면, 신규 업로드에 대해 503 또는 429 응답.

- **우선순위** (v1에서는 단일 우선순위만 사용 가능하나, 확장 여지 고려)
  - 향후 유료/내부 사용자 우선 처리 같은 시나리오를 지원하기 위해, Job에 `priority` 필드를 둘 수 있음.

### 4.2 API Rate Limit

- 클라이언트 단위(예: IP 또는 인증된 사용자 ID) Rate Limit 정책 정의
  - 예: `/upload`는 사용자당 분당 N회, 시간당 M회 제한.

- 구현 방법 예시
  - API Gateway 레벨 Rate Limit
  - 혹은 애플리케이션 레벨에서 Redis 기반 토큰 버킷/슬라이딩 윈도우 알고리즘 사용.

### 4.3 워커 동시성 제어

- Celery/RQ 워커 프로세스/스레드 수를 제한
  - 워커 수 = CPU/메모리 및 LLM API Rate Limit를 고려해 결정.

- LLMClient 레벨 동시성 제한
  - 내부 세마포어/큐를 사용해 동시에 날리는 LLM 요청 개수를 제한.

---

## 5. 번역 중단/실패 시 일관성 및 재시도 전략

### 5.1 실패 유형 구분

- **일시 오류**
  - 네트워크 타임아웃, LLM API 5xx, 일시적인 Rate Limit 초과 등.

- **영구 오류**
  - 지원하지 않는 파일 형식, PDF 파싱 불가, 손상된 파일, LLM 입력 한도 초과 등.

### 5.2 재시도 정책

- 청크 단위 재시도
  - 일시 오류에 대해서는 동일 청크 재시도(예: 최대 3회, 지수 백오프).

- 전체 Job 재시도
  - 운영자/관리 콘솔에서 수동 재시도 트리거.
  - 자동 전체 재시도는 기본적으로 하지 않음(비용 폭증 방지).

### 5.3 일관성 보장

- 부분 번역 상태 방지
  - 번역 실패 시, 사용자가 `/download`를 호출해도 **불완전한 PDF**를 받지 않도록 함.
  - 정책: 모든 필수 청크 번역 및 PDF 생성이 완료된 경우에만 `COMPLETED`로 전이.

- 상태/로그 기록
  - 실패 시 `Job.error_code`, `error_message`를 반드시 설정.
  - 나중에 재현/분석이 가능하도록 주요 파라미터/환경 정보를 로그에 남김.

---

## 6. 모니터링 및 알림

### 6.1 주요 메트릭

- 요청 단위
  - `/upload` 요청 수, 성공/실패 비율
  - `/status` 응답 시간
  - `/download` 요청 수 및 실패 비율

- Job 단위
  - Job 생성/완료/실패 수
  - 평균/중앙/최악 Job 처리 시간
  - Job 상태별( PENDING/RUNNING ) 개수

- LLM/인프라 단위
  - LLM 요청 수, 실패율, 평균 응답 시간
  - 워커 큐 길이, 워커 활성 수
  - 스토리지 용량 사용량(원본/번역 파일)

### 6.2 알림 기준

- 실패율 급증
  - 일정 기간(예: 5분) 내 실패율이 임계치(예: 5% 이상)를 넘을 때 알림.

- 큐 길이 증가
  - PENDING Job이 설정된 상한의 일정 비율(예: 70%) 이상으로 장시간 유지될 때 알림.

- LLM/API 오류
  - 외부 LLM 서비스 5xx 빈도 상승, Rate Limit 초과 빈도 증가 시 알림.

---

## 7. 용량 계획 및 스케일링 전략

### 7.1 초기 용량 가정

- 하루 처리 예상 논문 수, 평균 페이지 수, 평균 토큰 수를 기준으로 초기 워커 수/인스턴스 사양을 계획.

### 7.2 스케일링 전략

- **수평 스케일링**
  - 워커 인스턴스 수를 늘려 Job 병렬 처리량 증가.

- **수직 스케일링**
  - PDF 파싱/렌더링이 병목일 경우 CPU/메모리 스펙을 상향.

- LLM API Rate Limit와의 관계
  - 인스턴스 수를 늘리더라도 외부 LLM API의 Rate Limit를 넘어서는 안 되므로, LLMClient 레벨에서 전역 동시성/초당 요청 수를 제어.

---

## 8. 요약

- 본 문서는 논문 번역 서비스의 성능/운영 관점에서
  - 업로드 용량/페이지 제한,
  - 토큰/비용/응답 속도 관리,
  - 큐/동시성/Rate Limit 정책,
  - 실패/재시도/일관성 전략,
  - 모니터링/알림,
  - 용량 계획 및 스케일링 전략
  을 정의합니다.

이 정의를 기반으로 운영 환경에서의 안정성과 비용 효율성을 확보하는 것을 목표로 합니다.
